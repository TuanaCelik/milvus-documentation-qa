{"content": "<iframe src=\"https://www.googletagmanager.com/ns.html?id=G-V1G3KQ048M\" height=\"0\" width=\"0\" style=\"display: none; visibility: hidden\" aria-hidden=\"true\"></iframe>DocsTutorialsToolsBlogCommunityTry Managed Milvus FREEDocsTutorialsToolsBlogCommunityStars22kJoin SlackTry Managed Milvus FREEHow we use cookiesThis website stores cookies on your computer. By continuing to browse or by clicking \u2018Accept\u2019, you agree to the storing of cookies on your device to enhance your site experience and for analytical purposes.AcceptSearch\u2318KHomev2.2.x\u200bAbout MilvusGet StartedUser GuideAdministration GuideIntegrationsBenchmarksToolsReferenceArchitectureBitsetBoolean Expression RulesConsistencyCoordinator HAGlossaryIn-memory ReplicaKnowhereSchemaDynamic SchemaJSONSimilarity MetricsPartition KeyMulti-tenancySystem ConfigurationsTimestampTime SynchronizationTime TravelUsers and RolesVector IndexIn-memory IndexOn-disk IndexScalar IndexExample ApplicationsFAQsAPI referenceIn-memory Index\nThis topic lists various types of in-memory indexes Milvus supports, scenarios each of them best suits, and parameters users can configure to achieve better search performance. For on-disk indexes, see On-disk Index.\nIndexing is the process of efficiently organizing data, and it plays a major role in making similarity search useful by dramatically accelerating time-consuming queries on large datasets.\nTo improve query performance, you can specify an index type for each vector field.\n \nCurrently, a vector field only supports one index type. Milvus automatically deletes the old index when switching the index type.\n\nANNS vector indexes\nMost of the vector index types supported by Milvus use approximate nearest neighbors search (ANNS) algorithms. Compared with accurate retrieval, which is usually very time-consuming, the core idea of ANNS is no longer limited to returning the most accurate result, but only searching for neighbors of the target. ANNS improves retrieval efficiency by sacrificing accuracy within an acceptable range.\nAccording to the implementation methods, the ANNS vector index can be divided into four categories:\n\nTree-based index\nGraph-based index\nHash-based index\nQuantization-based index\n\nIndexes supported in Milvus\nAccording to the suited data type, the supported indexes in Milvus can be divided into two categories:\n\nIndexes for floating-point embeddings:\n\nFor 128-dimensional floating-point embeddings, the storage they take up is 128 * the size of float = 512 bytes. And the distance metrics used for float-point embeddings are Euclidean distance (L2) and Inner product.\nThis type of indexes include FLAT, IVF_FLAT, IVF_PQ, IVF_SQ8, ANNOY, and HNSW.\n\n\nIndexes for binary embeddings\n\nFor 128-dimensional binary embeddings, the storage they take up is 128 / 8 = 16 bytes. And the distance metrics used for binary embeddings are Jaccard, Tanimoto, Hamming, Superstructure, and Substructure.\nThis type of indexes include BIN_FLAT and BIN_IVF_FLAT.\n\n\n\nThe following table classifies the indexes that Milvus supports:\n\nFloating-point embeddings Binary embeddings\n\n\n\n\n  \n    Supported index\n    Classification\n    Scenario\n  \n\n\n  \n    FLAT\n    N/A\n    \n      \n        Relatively small dataset\n        Requires a 100% recall rate\n      \n    \n  \n  \n    IVF_FLAT\n    Quantization-based index\n    \n      \n        High-speed query\n        Requires a recall rate as high as possible\n      \n    \n  \n  \n    IVF_SQ8\n    Quantization-based index\n    \n      \n        High-speed query\n        Limited memory resources\n        Accepts minor compromise in recall rate\n      \n    \n    \n  \n    IVF_PQ\n    Quantization-based index\n    \n      \n        Very high-speed query\n        Limited memory resources\n        Accepts substantial compromise in recall rate\n      \n    \n  \n  \n    HNSW\n    Graph-based index\n    \n      \n        Very high-speed query\n        Requires a recall rate as high as possible\n        Large memory resources\n      \n    \n  \n  \n    ANNOY\n    Tree-based index\n    \n      \n        Low-dimensional vectors\n        Will be deprecated in new versions due to its low recall rate.\n      \n    \n  \n\n\nFLAT\nFor vector similarity search applications that require perfect accuracy and depend on relatively small (million-scale) datasets, the FLAT index is a good choice. FLAT does not compress vectors, and is the only index that can guarantee exact search results. Results from FLAT can also be used as a point of comparison for results produced by other indexes that have less than 100% recall.\nFLAT is accurate because it takes an exhaustive approach to search, which means for each query the target input is compared to every vector in a dataset. This makes FLAT the slowest index on our list, and poorly suited for querying massive vector data. There are no parameters required for the FLAT index in Milvus, and using it does not need data training.\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nmetric_type\n[Optional] The chosen distance metric.\nSee Supported Metrics.\n\n\n\n\n\nIVF_FLAT\nIVF_FLAT divides vector data into nlist cluster units, and then compares distances between the target input vector and the center of each cluster. Depending on the number of clusters the system is set to query (nprobe), similarity search results are returned based on comparisons between the target input and the vectors in the most similar cluster(s) only \u2014 drastically reducing query time.\nBy adjusting nprobe, an ideal balance between accuracy and speed can be found for a given scenario. Results from the IVF_FLAT performance test demonstrate that query time increases sharply as both the number of target input vectors (nq), and the number of clusters to search (nprobe), increase.\nIVF_FLAT is the most basic IVF index, and the encoded data stored in each unit is consistent with the original data.\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnlist\nNumber of cluster units\n[1, 65536]\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnprobe\nNumber of units to query\nCPU: [1, nlist]\n\n\n\n\n\nIVF_SQ8\nIVF_FLAT does not perform any compression, so the index files it produces are roughly the same size as the original, raw non-indexed vector data. For example, if the original 1B SIFT dataset is 476 GB, its IVF_FLAT index files will be slightly smaller (~470 GB). Loading all the index files into memory will consume 470 GB of storage.\nWhen disk, CPU, or GPU memory resources are limited, IVF_SQ8 is a better option than IVF_FLAT. This index type can convert each FLOAT (4 bytes) to UINT8 (1 byte) by performing Scalar Quantization (SQ). This reduces disk, CPU, and GPU memory consumption by 70\u201375%. For the 1B SIFT dataset, the IVF_SQ8 index files require just 140 GB of storage.\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnlist\nNumber of cluster units\n[1, 65536]\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnprobe\nNumber of units to query\nCPU: [1, nlist]\n\n\n\n\n\nIVF_PQ\nPQ (Product Quantization) uniformly decomposes the original high-dimensional vector space into Cartesian products of m low-dimensional vector spaces, and then quantizes the decomposed low-dimensional vector spaces. Instead of calculating the distances between the target vector and the center of all the units, product quantization enables the calculation of distances between the target vector and the clustering center of each low-dimensional space and greatly reduces the time complexity and space complexity of the algorithm.\nIVF_PQ performs IVF index clustering before quantizing the product of vectors. Its index file is even smaller than IVF_SQ8, but it also causes a loss of accuracy during searching vectors.\n\nIndex building parameters and search parameters vary with Milvus distribution. Select your Milvus distribution first.\n\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnlist\nNumber of cluster units\n[1, 65536]\n\n\nm\nNumber of factors of product quantization\ndim mod m == 0\n\n\nnbits\n[Optional] Number of bits in which each low-dimensional vector is stored.\n[1, 16] (8 by default)\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnprobe\nNumber of units to query\n[1, nlist]\n\n\n\n\n\nHNSW\nHNSW (Hierarchical Navigable Small World Graph) is a graph-based indexing algorithm. It builds a multi-layer navigation structure for an image according to certain rules. In this structure, the upper layers are more sparse and the distances between nodes are farther; the lower layers are denser and the distances between nodes are closer. The search starts from the uppermost layer, finds the node closest to the target in this layer, and then enters the next layer to begin another search. After multiple iterations, it can quickly approach the target position.\nIn order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to M. In addition, you can use efConstruction (when building index) or ef (when searching targets) to specify a search range.\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nM\nMaximum degree of the node\n[4, 64]\n\n\nefConstruction\nSearch scope\n[8, 512]\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nef\nSearch scope\n[top_k, 32768]\n\n\n\n\n\nANNOY\nANNOY (Approximate Nearest Neighbors Oh Yeah) is an index that uses a hyperplane to divide a high-dimensional space into multiple subspaces, and then stores them in a tree structure.\nThere are just two main parameters needed to tune ANNOY: the number of trees n_trees and the number of nodes to inspect during searching search_k.\n\n\nn_trees is provided during build time and affects the build time and the index size. A larger value will give more accurate results, but larger indexes.\n\n\nsearch_k is provided in runtime and affects the search performance. A larger value will give more accurate results, but will take longer time to return.\n\n\nIf search_k is not provided, it will default to n * n_trees where n is the number of approximate nearest neighbors. Otherwise, search_k and n_trees are roughly independent, i.e. the value of n_trees will not affect search time if search_k is held constant and vice versa. Basically it's recommended to set n_trees as large as possible given the amount of memory you can afford, and it's recommended to set search_k as large as possible given the time constraints you have for the queries.\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nn_trees\nThe number of trees.\n[1, 1024]\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nsearch_k\nThe parameters that controls the search scope.\n[k, inf]\n\n\n\n\n\n\n\n\n\n  \n    Supported index\n    Classification\n    Scenario\n  \n\n\n  \n    BIN_FLAT\n    N/A\n    \n      \n        Relatively small dataset\n        Requires a 100% recall rate\n      \n    \n  \n  \n    BIN_IVF_FLAT\n    Quantization-based index\n    \n      \n        High-speed query\n        Requires a recall rate as high as possible\n      \n    \n  \n\n\nBIN_FLAT\nThis index is exactly the same as FLAT except that this can only be used for binary embeddings.\nFor vector similarity search applications that require perfect accuracy and depend on relatively small (million-scale) datasets, the BIN_FLAT index is a good choice. BIN_FLAT does not compress vectors, and is the only index that can guarantee exact search results. Results from BIN_FLAT can also be used as a point of comparison for results produced by other indexes that have less than 100% recall.\nBIN_FLAT is accurate because it takes an exhaustive approach to search, which means for each query the target input is compared to vectors in a dataset. This makes BIN_FLAT the slowest index on our list, and poorly suited for querying massive vector data. There are no parameters for the BIN_FLAT index in Milvus, and using it does not require data training or additional storage.\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nmetric_type\n[Optional] The chosen distance metric.\nSee Supported Metrics.\n\n\n\n\n\nBIN_IVF_FLAT\nThis index is exactly the same as IVF_FLAT except that this can only be used for binary embeddings.\nBIN_IVF_FLAT divides vector data into nlist cluster units, and then compares distances between the target input vector and the center of each cluster. Depending on the number of clusters the system is set to query (nprobe), similarity search results are returned based on comparisons between the target input and the vectors in the most similar cluster(s) only \u2014 drastically reducing query time.\nBy adjusting nprobe, an ideal balance between accuracy and speed can be found for a given scenario. Query time increases sharply as both the number of target input vectors (nq), and the number of clusters to search (nprobe), increase.\nBIN_IVF_FLAT is the most basic BIN_IVF index, and the encoded data stored in each unit is consistent with the original data.\n\n\nIndex building parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnlist\nNumber of cluster units\n[1, 65536]\n\n\n\n\n\nSearch parameters\n\n\n\nParameter\nDescription\nRange\n\n\n\n\nnprobe\nNumber of units to query\nCPU: [1, nlist]\n\n\n\n\n\n\nFAQ\n\nWhat is the difference between FLAT index and IVF_FLAT index?\nIVF_FLAT index divides a vector space into nlist clusters. If you keep the default value of nlist as 16384, Milvus compares the distances between the target vector and the centers of all 16384 clusters to get nprobe nearest clusters. Then Milvus compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. Unlike IVF_FLAT, FLAT directly compares the distances between the target vector and each and every vector.\n\n\nTherefore, when the total number of vectors approximately equals nlist, IVF_FLAT and FLAT has little difference in the way of calculation required and search performance. But as the number of vectors grows to two times, three times, or n times of nlist, IVF_FLAT index begins to show increasingly greater advantages.\n\n\nSee How to Choose an Index in Milvus for more information.\n\n\nWhat's next\n\nLearn more about the Similarity Metrics supported in Milvus.\nindex.md was last updated at 2023-06-14 05:52:43: Release docs for 2.2.10Edit this pageReport a bugRequest doc changesOn this pageIn-memory IndexANNS vector indexesIndexes supported in MilvusFAQWhat's nextResourcesDocsBlogManaged serviceTutorialsBootcampDemoVideoToolsAttuMilvus CLISizing ToolMivlus backup ToolCommunityGet involvedSlackGithubForumMilvus. 2023 All rights reserved./*<![CDATA[*/window.pagePath=\"/docs/index.md\";/*]]>*//*<![CDATA[*/window.___chunkMapping={\"polyfill\":[\"/polyfill.js\"],\"app\":[\"/app.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js.js\",\"/component---src-pages-404-js.ffef32ceb6972d1b6709.css\"],\"component---src-pages-bootcamp-jsx\":[\"/component---src-pages-bootcamp-jsx.js\",\"/component---src-pages-bootcamp-jsx.edf1a55d3c49094e9b41.css\"],\"component---src-pages-community-index-jsx\":[\"/component---src-pages-community-index-jsx.js\",\"/component---src-pages-community-index-jsx.c505d2a5fff7c1e4b2c8.css\"],\"component---src-pages-index-jsx\":[\"/component---src-pages-index-jsx.js\",\"/component---src-pages-index-jsx.45df0d4bdfe2db469d6c.css\"],\"component---src-pages-milvus-demos-index-jsx\":[\"/component---src-pages-milvus-demos-index-jsx.js\",\"/component---src-pages-milvus-demos-index-jsx.1a3d1c4caf417de255ae.css\"],\"component---src-pages-milvus-demos-reverse-image-search-jsx\":[\"/component---src-pages-milvus-demos-reverse-image-search-jsx.js\",\"/component---src-pages-milvus-demos-reverse-image-search-jsx.c41e4c5ead83649937e8.css\"],\"component---src-pages-slack-jsx\":[\"/component---src-pages-slack-jsx.js\",\"/component---src-pages-slack-jsx.b3b356986d01fe89f9d1.css\"],\"component---src-pages-tools-sizing-jsx\":[\"/component---src-pages-tools-sizing-jsx.js\",\"/component---src-pages-tools-sizing-jsx.66d1c05015f9508df90b.css\"],\"component---src-templates-api-doc-template-jsx\":[\"/component---src-templates-api-doc-template-jsx.js\",\"/component---src-templates-api-doc-template-jsx.6c57c73b99682695a5ef.css\"],\"component---src-templates-blog-list-template-jsx\":[\"/component---src-templates-blog-list-template-jsx.js\",\"/component---src-templates-blog-list-template-jsx.71f592374d478c258caf.css\"],\"component---src-templates-blog-template-jsx\":[\"/component---src-templates-blog-template-jsx.js\",\"/component---src-templates-blog-template-jsx.5068317f62135173b013.css\"],\"component---src-templates-doc-template-jsx\":[\"/component---src-templates-doc-template-jsx.js\",\"/component---src-templates-doc-template-jsx.0e85fbce360982ff881c.css\"]};/*]]>*/", "content_type": "text", "score": null, "meta": {"url": "https://milvus.io/docs/index.md"}, "id_hash_keys": ["content"], "embedding": null, "id": "3a132e8e7070337c45731df2753c83e5"}